# Optimizing Online Advertisement Using Adaptive Learning Techniques

See our report here: [Optimizing_Online_Advertising_Using_Adaptive_Learning_Techniques.pdf](https://github.com/user-attachments/files/19274364/Optimizing_Online_Advertising_Using_Adaptive_Learning_Techniques.pdf)

## Introduction
In the evolving landscape of digital advertising, optimizing ad placements and bidding strategies in real-time remains a significant challenge for businesses. Traditional methods relying on historical data and static models often lead to suboptimal ad targeting and inefficient budget allocation. This project leverages adaptive learning techniques, including machine learning models and reinforcement learning-based Multi-Armed Bandits (MAB), to enhance ad click-through rates (CTR) and maximize return on investment (ROI).

## Methods
Using a Kaggle ad click prediction dataset, our approach integrates: 

• Predictive modeling: Machine learning algorithms (Logistic Regression, SVM, Random Forest, XGBoost, and LightGBM) to estimate the probability of user ad clicks. 

• Personalized ad positioning: Optimizing ad placement using logistic regression and gradient boosting models, ensuring better engagement. 

• Multi-Armed Bandit (MAB) strategies: Dynamically adjusting ad placements through an epsilon-greedy reinforcement learning framework to balance exploration and exploitation.

## Findings
Our findings highlight that XGBoost and LightGBM outperform traditional models, capturing complex user interactions and significantly improving ad placement recommendations. Moreover, MAB-driven adaptive ad selection surpassed a static baseline model, leading to an increase in CTR from 11.26% to 13.76% by dynamically allocating impressions to high-performing positions.

This project demonstrates that adaptive machine learning and reinforcement learning techniques offer superior ad targeting strategies, enabling businesses to reduce inefficient spending, improve engagement, and enhance marketing ROI in real-time digital advertising environments.

## Contributor
Ellie Yang, Yu He, Yuki Yu, Haibu Shi
